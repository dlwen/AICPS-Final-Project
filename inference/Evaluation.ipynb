{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyMU+WbhKu/VYXpJ0PDgBTBo"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","source":["! pip install jiwer"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"hQRNzH5rUyKy","executionInfo":{"status":"ok","timestamp":1745282154438,"user_tz":300,"elapsed":13483,"user":{"displayName":"lingwen Deng","userId":"09022343709927879672"}},"outputId":"f7ec6e83-669d-4aa8-974a-f443e8f48613"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting jiwer\n","  Downloading jiwer-3.1.0-py3-none-any.whl.metadata (2.6 kB)\n","Requirement already satisfied: click>=8.1.8 in /usr/local/lib/python3.11/dist-packages (from jiwer) (8.1.8)\n","Collecting rapidfuzz>=3.9.7 (from jiwer)\n","  Downloading rapidfuzz-3.13.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (12 kB)\n","Downloading jiwer-3.1.0-py3-none-any.whl (22 kB)\n","Downloading rapidfuzz-3.13.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.1 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.1/3.1 MB\u001b[0m \u001b[31m25.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hInstalling collected packages: rapidfuzz, jiwer\n","Successfully installed jiwer-3.1.0 rapidfuzz-3.13.0\n"]}]},{"cell_type":"code","source":["import os\n","from jiwer import wer, cer\n","from collections import defaultdict\n","import re\n","\n","def normalize_text(text):\n","    \"\"\"\n","    Normalize text by removing symbols, extra spaces, and converting to lowercase.\n","    \"\"\"\n","    # Remove all symbols and punctuation except alphanumeric and spaces\n","    text = re.sub(r'[^\\w\\s]', '', text)\n","    # Convert to lowercase\n","    text = text.lower()\n","    # Replace multiple spaces with a single space\n","    text = re.sub(r'\\s+', ' ', text)\n","    # Strip leading and trailing spaces\n","    text = text.strip()\n","    return text\n","\n","def load_transcripts(folder_path, strip_prefix=\"\", strip_suffix=\"\"):\n","    \"\"\"\n","    Reads all .txt files and returns a dict: core_name -> transcript\n","    Strips prefix and suffix from filename to get core_name.\n","    \"\"\"\n","    transcripts = {}\n","    for filename in os.listdir(folder_path):\n","        if filename.lower().endswith(\".txt\"):\n","            key = filename\n","            if strip_prefix and key.startswith(strip_prefix):\n","                key = key[len(strip_prefix):]\n","            if strip_suffix and key.endswith(strip_suffix):\n","                key = key[:-len(strip_suffix)]\n","            file_path = os.path.join(folder_path, filename)\n","            with open(file_path, \"r\", encoding=\"utf-8\") as f:\n","                # Apply normalization to remove symbols\n","                transcripts[key] = normalize_text(f.read().strip())\n","    return transcripts\n","\n","def evaluate_asr(gt_folder, pred_folder):\n","    gt_transcripts = load_transcripts(gt_folder, strip_prefix=\"transcription_\")\n","    pred_transcripts = load_transcripts(pred_folder)\n","\n","    # Match by core names\n","    common_keys = sorted(set(gt_transcripts) & set(pred_transcripts))\n","    if not common_keys:\n","        print(\"No matching files found. Check naming conventions.\")\n","        return {}\n","\n","    per_file = {}\n","    refs, hyps, wer_list, cer_list = [], [], [], []\n","\n","    for key in common_keys:\n","        ref = gt_transcripts[key]\n","        hyp = pred_transcripts[key]\n","\n","        w = wer(ref, hyp)\n","        c = cer(ref, hyp)\n","\n","        per_file[key] = {\"wer\": w, \"cer\": c}\n","        refs.append(ref)\n","        hyps.append(hyp)\n","        wer_list.append(w)\n","        cer_list.append(c)\n","\n","    return {\n","        \"per_file\": per_file,\n","        \"average_wer\": sum(wer_list)/len(wer_list),\n","        \"average_cer\": sum(cer_list)/len(cer_list),\n","        \"corpus_wer\": wer(refs, hyps),\n","        \"corpus_cer\": cer(refs, hyps),\n","    }\n","\n","def compute_group_wise_averages(per_file_results):\n","    \"\"\"\n","    Computes average WER and CER for each group (e.g., 'noisy', 'midnoise', 'quite')\n","    based on the prefix of the file name.\n","    \"\"\"\n","    group_scores = defaultdict(lambda: {\"wer\": [], \"cer\": []})\n","\n","    for fname, scores in per_file_results.items():\n","        group_name = fname.split('_')[0]  # e.g., 'noisy' from 'noisy_1.txt'\n","        group_scores[group_name][\"wer\"].append(scores[\"wer\"])\n","        group_scores[group_name][\"cer\"].append(scores[\"cer\"])\n","\n","    group_averages = {}\n","    for group, scores in group_scores.items():\n","        avg_wer = sum(scores[\"wer\"]) / len(scores[\"wer\"])\n","        avg_cer = sum(scores[\"cer\"]) / len(scores[\"cer\"])\n","        group_averages[group] = {\"average_wer\": avg_wer, \"average_cer\": avg_cer}\n","\n","    return group_averages\n","\n","def run_evaluation():\n","    print(\"Running evaluation with symbol normalization...\")\n","\n","    # ASR results\n","    gt_folder = \"data/transcription\"\n","    pre_folder = \"data/ASR_result\"\n","    print(\"\\nASR Evaluation:\")\n","    results = evaluate_asr(gt_folder, pre_folder)\n","    group_results = compute_group_wise_averages(results[\"per_file\"])\n","    for group, metrics in group_results.items():\n","        print(f\"{group}: WER = {metrics['average_wer']:.2%}, CER = {metrics['average_cer']:.2%}\")\n","    print(f\"Overall: WER = {results['corpus_wer']:.2%}, CER = {results['corpus_cer']:.2%}\")\n","\n","    # VSR results\n","    pre_folder = \"data/VSR_result\"\n","    print(\"\\nVSR Evaluation:\")\n","    results = evaluate_asr(gt_folder, pre_folder)\n","    group_results = compute_group_wise_averages(results[\"per_file\"])\n","    for group, metrics in group_results.items():\n","        print(f\"{group}: WER = {metrics['average_wer']:.2%}, CER = {metrics['average_cer']:.2%}\")\n","    print(f\"Overall: WER = {results['corpus_wer']:.2%}, CER = {results['corpus_cer']:.2%}\")\n","\n","    # Multimodal results\n","    pre_folder = \"data/multimodal_result\"\n","    print(\"\\nMultimodal Evaluation:\")\n","    results = evaluate_asr(gt_folder, pre_folder)\n","    group_results = compute_group_wise_averages(results[\"per_file\"])\n","    for group, metrics in group_results.items():\n","        print(f\"{group}: WER = {metrics['average_wer']:.2%}, CER = {metrics['average_cer']:.2%}\")\n","    print(f\"Overall: WER = {results['corpus_wer']:.2%}, CER = {results['corpus_cer']:.2%}\")\n","\n"],"metadata":{"id":"lni3kj8a-VDc"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["run_evaluation()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"FHGFM_HjU7ta","executionInfo":{"status":"ok","timestamp":1745283089196,"user_tz":300,"elapsed":741,"user":{"displayName":"lingwen Deng","userId":"09022343709927879672"}},"outputId":"764177a5-0bd1-4ad8-d594-1af403e92b7e"},"execution_count":12,"outputs":[{"output_type":"stream","name":"stdout","text":["Running evaluation with symbol normalization...\n","\n","ASR Evaluation:\n","midnoise: WER = 9.95%, CER = 7.26%\n","noisy: WER = 100.94%, CER = 85.61%\n","quite: WER = 8.95%, CER = 2.48%\n","Overall: WER = 39.80%, CER = 30.73%\n","\n","VSR Evaluation:\n","midnoise: WER = 31.08%, CER = 21.11%\n","noisy: WER = 37.27%, CER = 27.13%\n","quite: WER = 27.18%, CER = 17.90%\n","Overall: WER = 31.89%, CER = 21.55%\n","\n","Multimodal Evaluation:\n","midnoise: WER = 21.54%, CER = 14.92%\n","noisy: WER = 37.27%, CER = 27.13%\n","quite: WER = 14.77%, CER = 7.79%\n","Overall: WER = 25.00%, CER = 16.47%\n"]}]}]}